{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f260b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pacha\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # parent of MetaWeightingModel\n",
    "sys.path.append(base_path)\n",
    "from TraitPredictionModel.ModelArchitecture.DenseNetModel import DenseNet121WheatModel\n",
    "from TraitPredictionModel.ModelArchitecture.EfficientNetV2Model import EfficientNetV2SWheatCountWithConfidence\n",
    "from TraitPredictionModel.ModelArchitecture.EfficientNetV2MModel import EfficientNetV2MWheatModelWithConfidence\n",
    "from TraitPredictionModel.ModelArchitecture.RegNetY8GFModel import RegNetY8GFModel\n",
    "from TraitPredictionModel.ModelArchitecture.EfficientNetV2MAddextrainputModel import EfficientNetV2MConfidenceAddeonextrainput\n",
    "from TraitPredictionModel.ModelArchitecture.RegNetY8GFAddextrainputModel import RegNetY8GFConfidenceAddoneextrainput\n",
    "from TraitPredictionModel.dataClass import WheatEarDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f0f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDevice():\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = \"mps\"  # Use Apple Metal (Mac M1/M2)\n",
    "        torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    elif torch.cuda.is_available():\n",
    "        device = \"cuda\"  # Use NVIDIA CUDA (Windows RTX 4060)\n",
    "    else:\n",
    "        device = \"cpu\"  # Default to CPU if no GPU is available\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device\n",
    "\n",
    "def loadFullData(dataPath):\n",
    "    df = pd.read_csv(dataPath)\n",
    "    print(f\"Loaded full dataset → Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "    return df\n",
    "\n",
    "def createLoader_full(df, traitName, extra_input_cols=None, batch_size=16, shuffle=False):\n",
    "    \"\"\"\n",
    "    Create a single DataLoader from the full DataFrame.\n",
    "    \"\"\"\n",
    "    dataset = WheatEarDataset(df, label_col=traitName, extra_input_cols=extra_input_cols)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
    "\n",
    "    print(f\"Full DataLoader created → Batches: {len(loader)}\")\n",
    "    return loader\n",
    "\n",
    "def testModelForPrepareData(model, test_loader, device, traitName, output_csv):\n",
    "    model.eval()\n",
    "    preds, stds, targets, datakeys = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            if len(batch) == 4:\n",
    "                rgb_batch, dsm_batch, label_batch, datakey_batch = batch\n",
    "            else:\n",
    "                rgb_batch, dsm_batch, _, label_batch, datakey_batch = batch\n",
    "\n",
    "            rgb_batch = rgb_batch.to(device)\n",
    "            dsm_batch = dsm_batch.to(device)\n",
    "\n",
    "            output = model(rgb_batch, dsm_batch)\n",
    "            pred_mean = output[:, 0].cpu().numpy()\n",
    "            pred_std = (torch.exp(0.5 * output[:, 1])).cpu().numpy()\n",
    "            label_batch = label_batch.squeeze().cpu().numpy()\n",
    "\n",
    "            preds.extend(pred_mean)\n",
    "            stds.extend(pred_std)\n",
    "            targets.extend(label_batch)\n",
    "            datakeys.extend(datakey_batch)\n",
    "\n",
    "    r2 = r2_score(targets, preds)\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    rmse = root_mean_squared_error(targets, preds)\n",
    "\n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"R² Score : {r2:.4f}\")\n",
    "    print(f\"MAE      : {mae:.4f}\")\n",
    "    print(f\"RMSE     : {rmse:.4f}\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"DataKey\": datakeys,\n",
    "        \"true_\" + traitName : targets,\n",
    "        \"predicted_\" + traitName : preds,\n",
    "        \"predicted_std_\" + traitName : stds,\n",
    "    })\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved predictions to: {output_csv}\")\n",
    "\n",
    "    return df, r2, mae, rmse\n",
    "\n",
    "def predictModelFullData(dataPath, traitName, model, modelPath):\n",
    "    '''\n",
    "    set data, device and test model\n",
    "    '''\n",
    "    # get data\n",
    "    full_df = loadFullData(dataPath)\n",
    "    full_loader = createLoader_full(full_df, traitName)\n",
    "    \n",
    "    # set device\n",
    "    device = setDevice()\n",
    "\n",
    "    # load model\n",
    "    loadedModel = model().to(device)\n",
    "    if(device == \"cuda\"):\n",
    "        loadedModel.load_state_dict(torch.load(modelPath))\n",
    "    else:\n",
    "        loadedModel.load_state_dict(torch.load(modelPath, map_location=torch.device(\"cpu\")))\n",
    "    loadedModel.eval()\n",
    "\n",
    "    print(\"traitName: \", traitName)\n",
    "    print(\"model: \", model.__name__)\n",
    "\n",
    "    saveFileName = \"predicted_\" + traitName + \"_\" +  model.__name__ + \".csv\"\n",
    "\n",
    "    # Run test\n",
    "    testModelForPrepareData(loadedModel, full_loader, device, traitName, saveFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictModelFullData(\"DataKey_RGB_DSM_LAI_SPAD_Height_totalSeedNum_totalSeedWeightAfterDry_totEarNum_totEarWeight_day_Raw1.csv\", \"days\", DenseNet121WheatModel, \"./TraitModel/days_DenseNet121WheatModel_from3.pth\")\n",
    "predictModelFullData(\"DataKey_RGB_DSM_LAI_SPAD_Height_totalSeedNum_totalSeedWeightAfterDry_totEarNum_totEarWeight_day_Raw1.csv\", \"Height\", DenseNet121WheatModel, \"./TraitModel/Height_DenseNet121WheatModel.pth\")\n",
    "predictModelFullData(\"DataKey_RGB_DSM_LAI_SPAD_Height_totalSeedNum_totalSeedWeightAfterDry_totEarNum_totEarWeight_day_Raw1.csv\", \"LAI\", EfficientNetV2SWheatCountWithConfidence, \"./TraitModel/LAI_EfficientNetV2SWheatCountWithConfidence.pth\")\n",
    "predictModelFullData(\"DataKey_RGB_DSM_LAI_SPAD_Height_totalSeedNum_totalSeedWeightAfterDry_totEarNum_totEarWeight_day_Raw1.csv\", \"SPAD\", EfficientNetV2SWheatCountWithConfidence, \"./TraitModel/SPAD_EfficientNetV2SWheatCountWithConfidence.pth\")\n",
    "predictModelFullData(\"DataKey_RGB_DSM_LAI_SPAD_Height_totalSeedNum_totalSeedWeightAfterDry_totEarNum_totEarWeight_day_Raw1.csv\", \"totalSeedNum\", DenseNet121WheatModel, \"./TraitModel/totalSeedNum_DenseNet121WheatModel.pth\")\n",
    "predictModelFullData(\"DataKey_RGB_DSM_LAI_SPAD_Height_totalSeedNum_totalSeedWeightAfterDry_totEarNum_totEarWeight_day_Raw1.csv\", \"totalSeedWeightAfterDry\", DenseNet121WheatModel, \"./TraitModel/totalSeedWeightAfterDry_DenseNet121WheatModel.pth\")\n",
    "predictModelFullData(\"DataKey_RGB_DSM_LAI_SPAD_Height_totalSeedNum_totalSeedWeightAfterDry_totEarNum_totEarWeight_day_Raw1.csv\", \"totEarNum\", DenseNet121WheatModel, \"./TraitModel/totEarNum_DenseNet121WheatModel.pth\")\n",
    "predictModelFullData(\"DataKey_RGB_DSM_LAI_SPAD_Height_totalSeedNum_totalSeedWeightAfterDry_totEarNum_totEarWeight_day_Raw1.csv\", \"totEarWeight\", DenseNet121WheatModel, \"./TraitModel/totEarWeight_DenseNet121WheatModel0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9f0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_trait_predictions(csv_paths, output_path=\"merged_predictions.csv\"):\n",
    "    \"\"\"\n",
    "    Merge multiple prediction CSV files horizontally based on 'DataKey'.\n",
    "    Assumes each file shares the same order and values for 'DataKey'.\n",
    "\n",
    "    Args:\n",
    "        csv_paths (list): List of CSV file paths to merge.\n",
    "        output_path (str): File path to save the merged result.\n",
    "    \"\"\"\n",
    "    merged_df = None\n",
    "\n",
    "    for i, path in enumerate(csv_paths):\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # Drop duplicate 'DataKey' columns except from first file\n",
    "        if i == 0:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            df = df.drop(columns=[\"DataKey\"])\n",
    "            merged_df = pd.concat([merged_df, df], axis=1)\n",
    "\n",
    "        print(f\"Loaded: {path} → Shape: {df.shape}\")\n",
    "\n",
    "    print(f\"\\nFinal merged shape: {merged_df.shape}\")\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved merged CSV to: {output_path}\")\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc5fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: predicted_days_DenseNet121WheatModel.csv → Shape: (26780, 4)\n",
      "Loaded: predicted_Height_DenseNet121WheatModel.csv → Shape: (26780, 3)\n",
      "Loaded: predicted_LAI_EfficientNetV2SWheatCountWithConfidence.csv → Shape: (26780, 3)\n",
      "Loaded: predicted_SPAD_EfficientNetV2SWheatCountWithConfidence.csv → Shape: (26780, 3)\n",
      "Loaded: predicted_totalSeedNum_DenseNet121WheatModel.csv → Shape: (26780, 3)\n",
      "Loaded: predicted_totalSeedWeightAfterDry_DenseNet121WheatModel.csv → Shape: (26780, 3)\n",
      "Loaded: predicted_totEarNum_DenseNet121WheatModel.csv → Shape: (26780, 3)\n",
      "Loaded: predicted_totEarWeight_DenseNet121WheatModel.csv → Shape: (26780, 3)\n",
      "\n",
      "Final merged shape: (26780, 25)\n",
      "Saved merged CSV to: meta_input_data.csv\n"
     ]
    }
   ],
   "source": [
    "csv_files = [\n",
    "    \"predicted_days_DenseNet121WheatModel.csv\",\n",
    "    \"predicted_Height_DenseNet121WheatModel.csv\",\n",
    "    \"predicted_LAI_EfficientNetV2SWheatCountWithConfidence.csv\",\n",
    "    \"predicted_SPAD_EfficientNetV2SWheatCountWithConfidence.csv\",\n",
    "    \"predicted_totalSeedNum_DenseNet121WheatModel.csv\",\n",
    "    \"predicted_totalSeedWeightAfterDry_DenseNet121WheatModel.csv\",\n",
    "    \"predicted_totEarNum_DenseNet121WheatModel.csv\",\n",
    "    \"predicted_totEarWeight_DenseNet121WheatModel.csv\"\n",
    "]\n",
    "\n",
    "merged_df = merge_trait_predictions(csv_files, output_path=\"meta_input_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385c2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
